{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxer3_88ZNq9"
   },
   "outputs": [],
   "source": [
    "#filenames for loading VPoser VAE network, neutral SMPL body model, AMASS sample data\n",
    "\n",
    "from os import path as osp\n",
    "\n",
    "support_dir = './VPoserModelFiles/'\n",
    "\n",
    "expr_dir = osp.join(support_dir,'vposer_v2_05/') #'TRAINED_MODEL_DIRECTORY'\n",
    "bm_fname =  osp.join(support_dir,'smplx_neutral_model.npz')    #'PATH_TO_SMPLX_model.npz'  neutral smpl body model\n",
    "sample_amass_fname = osp.join(support_dir, 'amass_sample.npz')  # a sample npz file from AMASS\n",
    "\n",
    "\n",
    "print(expr_dir)\n",
    "print(bm_fname)\n",
    "print(sample_amass_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znBXfPLIZmXK"
   },
   "outputs": [],
   "source": [
    "#Loading SMPLx Body Model\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Choose the device to run the body model on, cuda or cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device is', device)\n",
    "\n",
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "bm = BodyModel(bm_fname=bm_fname).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-96bbSCcBuz"
   },
   "outputs": [],
   "source": [
    "#Loading VPoser VAE Body Pose Prior\n",
    "from human_body_prior.tools.model_loader import load_model\n",
    "from human_body_prior.models.vposer_model import VPoser\n",
    "\n",
    "vp, ps = load_model(expr_dir, model_code=VPoser,\n",
    "                              remove_words_in_model_weights='vp_model.',\n",
    "                              disable_grad=True,\n",
    "                              comp_device=device)\n",
    "vp = vp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import build_trainer\n",
    "\n",
    "trainer = build_trainer()\n",
    "trainer.load_model(\"./snapshot/model-iter-2400.pth\")\n",
    "\n",
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input, target) = trainer.dataloader.dataset[12] # test set\n",
    "\n",
    "# [input (50, 32), target (25, 32)]\n",
    "\n",
    "# [input (50, 32)] ---> My MLP Model -> [pred (50, 32)]\n",
    "# pred = pred[:, :target_length] -> [pred (25, 32)]\n",
    "\n",
    "input = input.unsqueeze(0).to(\"cuda\")\n",
    "target = target.unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "print(input.shape)\n",
    "print(target.shape)\n",
    "\n",
    "pred = trainer.model(input)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1CVZk4Ef8zt"
   },
   "outputs": [],
   "source": [
    "# Prepare the body poses from amass sample file\n",
    "#  indexing [3:66] removes global rotation, hands/fingers, and anything else other than 21 major body joints\n",
    "# amass_body_pose = np.load(sample_amass_fname)['poses'][:, 3:66]\n",
    "# amass_body_pose = torch.from_numpy(amass_body_pose).type(torch.float).to(device)\n",
    "# print('amass_body_pose.shape', amass_body_pose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwhSKj0XgJmy"
   },
   "outputs": [],
   "source": [
    "# run the encoder on all frames\n",
    "# amass_body_poZ = vp.encode(amass_body_pose).mean\n",
    "# print('amass_body_poZ.shape', amass_body_poZ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seEPQGOpgL4J"
   },
   "outputs": [],
   "source": [
    "# run the decoder on all frames\n",
    "# amass_body_pose_rec = vp.decode(amass_body_poZ)['pose_body'].contiguous().view(-1, 63)\n",
    "# print('amass_body_pose_rec.shape', amass_body_pose_rec.shape)\n",
    "target_rec = vp.decode(target)['pose_body'].contiguous().view(-1, 63)\n",
    "pred_rec = vp.decode(pred)['pose_body'].contiguous().view(-1, 63)\n",
    "\n",
    "print(target_rec.shape)\n",
    "print(pred_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASdmx8xmzpQp"
   },
   "outputs": [],
   "source": [
    "#get vertices and faces of a polygonal mesh model for each body pose\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "import trimesh\n",
    "\n",
    "originalPoses = {'pose_body': target_rec}\n",
    "recoveredPoses = {'pose_body': pred_rec}\n",
    "\n",
    "bmodelorig = bm(**originalPoses);\n",
    "bmodelreco = bm(**recoveredPoses);\n",
    "vorig = c2c(bmodelorig.v)\n",
    "vreco = c2c(bmodelreco.v)\n",
    "faces = c2c(bm.f)\n",
    "\n",
    "T, num_verts = vorig.shape[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Hqh4Fe3ja4"
   },
   "outputs": [],
   "source": [
    "#visualize one frame's body pose before (grey) and after (purple) encode-decode\n",
    "fIdx = 10\n",
    "verts = vorig[fIdx]\n",
    "mesh1 = trimesh.base.Trimesh(verts, faces)\n",
    "mesh1.visual.vertex_colors = [254, 254, 254]\n",
    "verts = vreco[fIdx]\n",
    "mesh2 = trimesh.base.Trimesh(verts, faces)\n",
    "mesh2.visual.vertex_colors = [254, 66, 200]\n",
    "mesh2.apply_translation([1, 0, 0])  #use [0,0,0] to overlay them on each other\n",
    "meshes = [mesh1, mesh2]\n",
    "trimesh.Scene(meshes).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WzyGrR8L-Gmh"
   },
   "outputs": [],
   "source": [
    "#visualize a temporal subsequence of poses spatially (use mouse to rotate view)\n",
    "#note that encoding followed by decoding is not a lossless process,\n",
    "#it can introduce a certain amount of error all by itself\n",
    "\n",
    "meshes = []\n",
    "for fIdx in range(25):\n",
    "    verts = vorig[fIdx]\n",
    "    mesh1 = trimesh.base.Trimesh(verts, faces)\n",
    "    mesh1.visual.vertex_colors = [254, 254, 254]\n",
    "    mesh1.apply_translation([0, 0, fIdx*.07])\n",
    "    meshes.append(mesh1)\n",
    "    verts = vreco[fIdx]\n",
    "    mesh1 = trimesh.base.Trimesh(verts, faces)\n",
    "    mesh1.visual.vertex_colors = [254, 150, 200]\n",
    "    mesh1.apply_translation([0, 0, fIdx*.07])\n",
    "    meshes.append(mesh1)\n",
    "\n",
    "trimesh.Scene(meshes).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3ztwAADQmjg"
   },
   "outputs": [],
   "source": [
    "# extract and visualize 23 body joints before and after encode-decode process\n",
    "# for a pose where error between original pose and decoded pose is rather large.\n",
    "# why 23 instead of 21 mentioned earlier?  There are two extra joints somewhere\n",
    "# that are not among the 21 rotatable body joints used by VPoser.\n",
    "\n",
    "fIdx = 10\n",
    "\n",
    "verts = vorig[fIdx]\n",
    "mesh1 = trimesh.base.Trimesh(verts, faces)\n",
    "mesh1.visual.vertex_colors = [254, 254, 254]\n",
    "verts = vreco[fIdx]\n",
    "mesh2 = trimesh.base.Trimesh(verts, faces)\n",
    "mesh2.visual.vertex_colors = [254, 66, 200]\n",
    "mesh2.apply_translation([0, 0, 0])  #use [0,0,0] to overlay them on each other\n",
    "meshes = [mesh1, mesh2]\n",
    "\n",
    "\n",
    "#get the 23 major 3D body joints\n",
    "joints = c2c(bmodelorig.Jtr[fIdx])\n",
    "origjoints = joints[0:23, :]   #ignore finger joints\n",
    "joints = c2c(bmodelreco.Jtr[fIdx])\n",
    "recojoints = joints[0:23, :]   #ignore finger joints\n",
    "\n",
    "print(origjoints.shape, recojoints.shape)\n",
    "for i in range(origjoints.shape[0]):\n",
    "    sphere = trimesh.primitives.Sphere(radius=.02, center=origjoints[i,:])\n",
    "    sphere.apply_translation([1, 0, 0])\n",
    "    sphere.visual.vertex_colors = [254, 254, 254]\n",
    "    meshes.append(sphere)\n",
    "    sphere = trimesh.primitives.Sphere(radius=.02, center=recojoints[i,:])\n",
    "    sphere.apply_translation([1, 0, 0])\n",
    "    sphere.visual.vertex_colors = [254, 150, 200]\n",
    "    meshes.append(sphere)\n",
    "\n",
    "trimesh.Scene(meshes).show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyML8a8Oe7psGsbZY8yY4iWd",
   "mount_file_id": "1J2upH87AU5O-RbSmWQA9v7gLLZ6XeNSX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vposer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
